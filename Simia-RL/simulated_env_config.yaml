defaults:
  - base
  - _self_


model_path: Simia-Agent/Simia-Tau-SFT-Qwen3-8B
micro_batch_size_per_gpu: 1
ppo_mini_batch_size: 8

actor_rollout_ref:
  actor:
    use_ref: True
    use_kl_loss: True
    kl_loss_coef: 0.001
    
    kl_loss_type: low_var_kl
    fsdp_config:
      model_dtype: bfloat16
      param_offload: False
      optimizer_offload: False
  rollout:
    max_model_len: 9000
    max_num_batched_tokens: 9000
    tensor_model_parallel_size: 1
    tp_size_check: False
    gpu_memory_utilization: 0.5
    temperature: 0.7
    rollout_filter_ratio: 1.0
    val_kwargs:
      do_sample: True
      temperature: 0.7
  ref:
    fsdp_config:
      model_dtype: bfloat16
      param_offload: False
      optimizer_offload: False

algorithm:
  adv_estimator: grpo

trainer:
  project_name: "simulated_env_tau2"
  experiment_name: "qwen-8b-SFT"
  n_gpus_per_node: 8
  val_before_train: False
  test_freq: 10000
  total_training_steps: 64
  save_freq: 4
  default_local_dir: "./outputs/checkpoints/Simia-RL-8B-tau2-APIGen-MT"
  logger: ['console', 'wandb']
  generations_to_log_to_wandb:
    train: 32
    val: 20

agent_proxy:
  max_turn: 40
  max_actions_per_turn: 1
  use_turn_scores: False
  reward_normalization:
    grouping: "state"
    method: "identity"

es_manager:
  train:
    env_groups: 16
    group_size: 8
    env_configs:
      tags: ["GeneralSimulated"]
      n_groups: [16]
  val:
    env_groups: 8
    group_size: 4
    env_configs:
      tags: ["GeneralSimulated"]
      n_groups: [8]

custom_envs:
  GeneralSimulated:
    env_type: simulated_general
    max_actions_per_traj: 60
    env_instruction: ""
    env_config:
      env_id: "null"
      output_dir: "./outputs/training_records/Simia-RL-8B-tau2-APIGen-MT/simulated_env_tau2/output"
      train_data_path: "./APIGen_5k_processed.json"
      training_record_dir: "./outputs/checkpoints/Simia-RL-8B-tau2-APIGen-MT/simulated_env_tau2/training_record"
      api_type: "openai"
      azure_endpoint: ""
      api_version: "2025-04-01-preview"
      deployment: "gpt-5"
      openai_api_key: ""
      openai_base_url: "https://api.openai.com/v1"
      openai_model: "gpt-5"
      temperature: 1.0
      max_tokens: 60000
      retry_attempts: 3
      timeout: 600
      simulator_mode: "base"
      max_simulation_steps: 100
      reward_on_success: 1.0
      reward_on_failure: 0.0

aml_checkpoints_path: "./outputs/checkpoints/Simia-RL-8B-tau2-APIGen-MT"
aml_output_dir: "./outputs/training_records/Simia-RL-8B-tau2-APIGen-MT"
